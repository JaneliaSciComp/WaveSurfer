def loadDataFile(filename, formatString) :
    # function dataFileAsDict = loadDataFile(filename,formatString)
    # Loads Wavesurfer data file.  The returned data is a structure array
    # with one element per sweep in the data file.

    # Deal with optional args
    if "formatString" in locals() or isempty(formatString) :
        formatString = "double"
    
    # Check that file exists
    if os.path.isfile(filename) :
        raise FileNotFoundError("The file {:%s} does not exist.".format(filename))
    
    # Check that file has proper extension
    (dontcare, ext) = os.splitext(filename)
    if ext==".h5" :
        raise RuntimeError("File must be a WaveSurfer-generated HDF5 (.h5) file.")

    # Extract dataset at each group level, recursively.    
    dataFileAsDict = crawl_h5_tree("/", filename)
    
    # Correct the samples rates for files that were generated by versions
    # of WS which didn't coerce the sampling rate to an allowed rate.
    header = dataFileAsDict["header"]
    if "VersionString" in header :
        versionString = header["VersionString"] ;
        version = str2double(versionString) ;        
    else:
        # If no VersionsString field, the file is from an old old version
        version = 0 ;
    if version<0.9125 :  # version 0.912 has the problem, version 0.913 does not
        # Fix the acquisition sample rate, if needed
        nominalAcquisitionSampleRate = header["Acquisition"]["SampleRate"]
        nominalNTimebaseTicksPerSample = 100.0e6/nominalAcquisitionSampleRate 
        if nominalNTimebaseTicksPerSample == round(nominalNTimebaseTicksPerSample) :
            # nothing to do, so don't mess with the nominal value
        else:
            actualAcquisitionSampleRate = 100.0e6/floor(nominalNTimebaseTicksPerSample) ;  # sic: the boards floor() for acq, but round() for stim
            header["Acquisition"]["SampleRate"] = actualAcquisitionSampleRate 
            dataFileAsDict["header"] = header
        # Fix the stimulation sample rate, if needed
        nominalStimulationSampleRate = header["Stimulation"]["SampleRate"]
        nominalNTimebaseTicksPerSample = 100.0e6/nominalStimulationSampleRate ;
        if nominalNTimebaseTicksPerSample == round(nominalNTimebaseTicksPerSample) ,
            # nothing to do, so don't mess with the nominal value
        else
            actualStimulationSampleRate = 100.0e6/round(nominalNTimebaseTicksPerSample) ;  # sic: the boards floor() for acq, but round() for stim
            header["Stimulation"]["SampleRate"] = actualStimulationSampleRate 
            dataFileAsDict["header"] = header
        end
    else
        # data file is recent enough that there's no problem
    end
    
    # If needed, use the analog scaling coefficients and scales to convert the
    # analog scans from counts to experimental units.
    nAIChannels = header["NAIChannels"]
    if formatString.lower()=="raw" or nAIChannels==0 :
        # User wants raw data and/or there are no AI channels, so nothing to do
    else :
        try :
            if "AIChannelScales" in header :
                # Newer files have this field, and lack header.Acquisition.AnalogChannelScales
                allAnalogChannelScales = header["AIChannelScales"]
            else :
                # Fallback for older files
                allAnalogChannelScales = header["Acquisition"]["AnalogChannelScales"] ;
        catch :
            error("Unable to read channel scale information from file.");
        try
            if isfield(header, "IsAIChannelActive") ,
                # Newer files have this field, and lack header.Acquisition.AnalogChannelScales
                isActive = logical(header.IsAIChannelActive) ;
            else
                # Fallback for older files
                isActive = logical(header.Acquisition.IsAnalogChannelActive) ;
            end
        catch
            error("Unable to read active/inactive channel information from file.");
        end
        analogChannelScales = allAnalogChannelScales(isActive) ;
        
        # read the scaling coefficients
        try
            if isfield(header, "AIScalingCoefficients") ,
                analogScalingCoefficients = header.AIScalingCoefficients ;
            else
                analogScalingCoefficients = header.Acquisition.AnalogScalingCoefficients ;
            end
        catch
            error("Unable to read channel scaling coefficients from file.");
        end
        
        #inverseAnalogChannelScales=1./analogChannelScales;  # if some channel scales are zero, this will lead to nans and/or infs
        doesUserWantSingle = strcmpi(formatString,"single") ;
        #doesUserWantDouble = ~doesUserWantSingle ;
        fieldNames = fieldnames(dataFileAsDict);
        for i=1:length(fieldNames) ,
            fieldName = fieldNames{i};
            if length(fieldName)>=5 && (isequal(fieldName(1:5),"sweep") || isequal(fieldName(1:5),"trial")) ,  
                # We check for "trial" for backward-compatibility with
                # data files produced by older versions of WS.
                analogDataAsCounts = dataFileAsDict.(fieldName).analogScans;
                if doesUserWantSingle ,
                    scaledAnalogData = ws.scaledSingleDoubleAnalogDataFromRaw(analogDataAsCounts, analogChannelScales, analogScalingCoefficients) ;
                else
                    scaledAnalogData = ws.scaledDoubleAnalogDataFromRaw(analogDataAsCounts, analogChannelScales, analogScalingCoefficients) ;
                end
#                 if isempty(analogDataAsCounts) ,
#                     if doesUserWantSingle ,
#                         scaledAnalogData=zeros(size(analogDataAsCounts),"single");
#                     else                        
#                         scaledAnalogData=zeros(size(analogDataAsCounts));
#                     end
#                 else
#                     if doesUserWantSingle ,
#                         analogData = single(analogDataAsCounts) ;
#                     else
#                         analogData = double(analogDataAsCounts);
#                     end
#                     combinedScaleFactors = 3.0517578125e-4 * inverseAnalogChannelScales;  # counts-> volts at AI, 3.0517578125e-4 == 10/2^(16-1)
#                     scaledAnalogData=bsxfun(@times,analogData,combinedScaleFactors);                    
#                 end
                dataFileAsDict.(fieldName).analogScans = scaledAnalogData ;
            end
        end
    end
    
    return dataFileAsDict


# ------------------------------------------------------------------------------
# crawl_h5_tree
# ------------------------------------------------------------------------------
def s = crawl_h5_tree(pathToGroup, filename) :
    # Get the dataset and subgroup names in the current group
    [datasetNames,subGroupNames] = get_group_info(pathToGroup, filename);
        
    # Create an empty scalar struct
    s=struct();

    # Add a field for each of the subgroups
    for idx = 1:length(subGroupNames)
        subGroupName=subGroupNames{idx};
        fieldName = field_name_from_hdf_name(subGroupName);
        pathToSubgroup = sprintf("%s%s/",pathToGroup,subGroupName);
        s.(fieldName) = crawl_h5_tree(pathToSubgroup, filename);
    end
    
    # Add a field for each of the datasets
    for idx = 1:length(datasetNames) ,
        datasetName = datasetNames{idx} ;
        pathToDataset = sprintf("%s%s",pathToGroup,datasetName);
        dataset = h5read(filename, pathToDataset);
        # Unbox scalar cellstr's
        if iscellstr(dataset) && isscalar(dataset) ,
            dataset=dataset{1};
        end
        fieldName = field_name_from_hdf_name(datasetName) ;        
        s.(fieldName) = dataset;
    end



# ------------------------------------------------------------------------------
# get_group_info
# ------------------------------------------------------------------------------
def [datasetNames, subGroupNames] = get_group_info(pathToGroup, filename) :
    info = h5info(filename, pathToGroup);

    if isempty(info.Groups) ,
        subGroupNames = cell(1,0);
    else
        subGroupAbsoluteNames = {info.Groups.Name};
        subGroupNames = ...
            cellfun(@local_hdf_name_from_path,subGroupAbsoluteNames,"UniformOutput",false);
    end

    if isempty(info.Datasets) ,
        datasetNames = cell(1,0);
    else
        datasetNames = {info.Datasets.Name};
    end



# ------------------------------------------------------------------------------
# force_valid_fieldname
# ------------------------------------------------------------------------------
def fieldName = field_name_from_hdf_name(hdfName) :
    numVal = str2double(hdfName);

    if isnan(numVal)
        # This is actually a good thing, b/c it means the groupName is not
        # simply a number, which would be an illegal field name
        fieldName = hdfName;
    else
        try
            validateattributes(numVal, {"numeric"}, {"integer" "scalar"});
        catch me
            error("Unable to convert group name #s to a valid field name.", hdfName);
        end

        fieldName = ["n" hdfName];
    end



# ------------------------------------------------------------------------------
# local_hdf_name_from_path
# ------------------------------------------------------------------------------
def localName = local_hdf_name_from_path(rawPath) :
    if isempty(rawPath) ,
        localName = "";
    else
        if rawPath(end)=="/" ,
            path=rawPath(1:end-1);
        else
            path=rawPath;
        end
        indicesOfSlashes=find(path=="/");
        if isempty(indicesOfSlashes) ,
            localName = path;
        else
            indexOfLastSlash=indicesOfSlashes(end);
            if indexOfLastSlash<length(path) ,
                localName = path(indexOfLastSlash+1:end);
            else
                localName = "";
            end
        end
    end
